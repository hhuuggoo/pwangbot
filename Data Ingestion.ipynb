{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing pwangbot\n",
    "\n",
    "I was chatting with @dff of @tidelift at the NumFocus summit last year, and he suggested classifying @pwang's tweets.  For those who don't know, @pwang tweets alot, and the content is quite good - but it spans a variety of subjects.  If you want to hear @pwang tweet about tech, but not about politics, it can be a problem.  So we're going to collect @pwang tweets, do some topic modeling, and then make some bots!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Tweets\n",
    "\n",
    "You won't be able to run this notebook - You need your own twtiter developer api credentials,\n",
    "but if you do that, you can inject those below.  We will use the twitter API (with the [tweepy](https://github.com/tweepy/tweepy/tree/master/tweepy) library) to download tweets, and then store them in S3.  \n",
    "\n",
    "[Saturn](https://www.saturncloud.io) manages S3 permissions and credentials for users.  If you want to run this notebook - you should create your own S3 bucket and credentials.  For writing to S3, we are using the [s3fs](https://github.com/dask/s3fs) Library which presents a very convenient file system oriented Python interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from os.path import join\n",
    "import s3fs\n",
    "import json\n",
    "with open(\"/home/jovyan/twitter-creds.json\") as f:\n",
    "    creds = json.load(f)['hhhuuugggooo']\n",
    "auth = tweepy.OAuthHandler(creds['consumer_key'], creds['consumer_secret'])\n",
    "auth.set_access_token(creds['access_token'], creds['access_token_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, timeout=120)\n",
    "twitter_username = 'pwang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "root = 'saturn-cloud-data/hugo/pwang-bot-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `api.user_timeline` method to retrieve tweets.  The `user_timeline` method takes a `page`, and `count` as parameters.  `count` is the number of `status` objects returned, We are setting `count` to 20.  `page` 1 returns the first 20 result, `page` 2 returns results 20-40, and so on.\n",
    "\n",
    "The call to `api.user_timeline` returns a list of `Status` objects.  We iterate over them and store the raw `json` representation to S3, keyed off of the `id` of the status update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 20\n",
    "\n",
    "def write2(page):\n",
    "    data = api.user_timeline(twitter_username, page=page, count=count)\n",
    "    for status in data:\n",
    "        with fs.open(join(root, str(status.id)), \"w\") as f:\n",
    "            f.write(json.dumps(status._json))\n",
    "    return len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask\n",
    "\n",
    "We're going to use a local Dask cluster to collect tweets in parallel. The Twitter API for querying a User "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dask.distributed import Client\n",
    "from distributed import LocalCluster\n",
    "cluster = LocalCluster(n_workers=2, threads_per_worker=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter only stores 3200 tweets.  Since we are processing 20 tweets per page, querying 161 pages should be more than enough to get all tweets that Twitter is storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we collected %s tweets 3215\n"
     ]
    }
   ],
   "source": [
    "fut = c.map(write2, range(161))\n",
    "counts = c.gather(fut)\n",
    "tweets = sum(counts)\n",
    "print('we collected %s tweets', tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3319"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs.ls(root))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
